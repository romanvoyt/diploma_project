{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libs\n",
    "from math import sqrt\n",
    "import random\n",
    "import os\n",
    "\n",
    "#default data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modules for data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/2year.xlsx')\n",
    "data['B'] = (data['B'].index > 9772).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.25366</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.3440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.2381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.31877</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16499</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.4660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29358</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.0066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.10823</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10124</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.9874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2        X3      X4      X5        X6       X7       X8  \\\n",
       "0  0.202350  0.46500  0.240380  1.5171 -14.547  0.510690  0.25366  0.91816   \n",
       "1  0.030073  0.59563  0.186680  1.3382 -37.859 -0.000319  0.04167  0.67890   \n",
       "2  0.257860  0.29949  0.665190  3.2211  71.799  0.000000  0.31877  2.33200   \n",
       "3  0.227160  0.67850  0.042784  1.0828 -88.212  0.000000  0.28505  0.47384   \n",
       "4  0.085443  0.38039  0.359230  1.9444  21.731  0.187900  0.10823  1.37140   \n",
       "\n",
       "        X9      X10  ...      X56       X57      X58      X59     X60  \\\n",
       "0  1.15190  0.42695  ...  0.13184  0.473950  0.86816  0.00024  8.5487   \n",
       "1  0.32356  0.40437  ...  0.12146  0.074369  0.87235  0.00000  1.5264   \n",
       "2  1.67620  0.69841  ...  0.16499  0.369210  0.81614  0.00000  4.3325   \n",
       "3  1.32410  0.32150  ...  0.29358  0.706570  0.78617  0.48456  5.2309   \n",
       "4  1.11260  0.52167  ...  0.10124  0.163790  0.89876  0.00000  5.7035   \n",
       "\n",
       "       X61      X62      X63      X64  B  \n",
       "0  5.16550  107.740  3.38790   5.3440  0  \n",
       "1  0.63305  622.660  0.58619   1.2381  0  \n",
       "2  3.19850   65.215  5.59690  47.4660  0  \n",
       "3  5.06750  142.460  2.56210   3.0066  0  \n",
       "4  4.00200   89.058  4.09840   5.9874  0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_headers(df):\n",
    "    cols = ['X' + str(i+1) for i in range(len(df.columns)-1)]\n",
    "    cols.append('Y')\n",
    "    df.columns = cols\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "mean_imputed_df = pd.DataFrame(imputer.fit_transform(data))\n",
    "set_new_headers(mean_imputed_df)\n",
    "\n",
    "data_imp = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = mean_imputed_df['Y'].values\n",
    "mean_imputed_df.drop('Y', axis=1, inplace=True)\n",
    "X = mean_imputed_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "nfolds = 10\n",
    "nclass = 2\n",
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "\n",
    "cross_val = StratifiedKFold(nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model objects\n",
    "## Tuning model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(model, features, model_name):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    results=pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\n",
    "    results=results.sort_values('importance', ascending=False)\n",
    "    results.head(70)\n",
    "#     results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh',\n",
    "#                      color = 'red', edgecolor = 'k', title = 'Feature Importances of ' + model_name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121 3052\n"
     ]
    }
   ],
   "source": [
    "ntrain=X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "nclass = 2\n",
    "SEED = 42\n",
    "NFOLDS = 10\n",
    "print(ntrain, ntest)\n",
    "kf = KFold(n_splits=NFOLDS, random_state=SEED, shuffle=True)\n",
    "labels = ['Normal','Bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    smote = ADASYN(sampling_strategy = 0.05, random_state=32)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        X=X_train[ttrain]\n",
    "        y=y_train[ttrain]\n",
    "        X_train_sm, y_train_sm= smote.fit_sample(X, y)\n",
    "        clf.fit(X_train_sm, y_train_sm)\n",
    "        sc = clf.score(X_train[ttest], y_train[ttest])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[ttest] = clf.predict_proba(X_train[ttest])\n",
    "        Xr_test += clf.predict_proba(X_test)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test\n",
    "\n",
    "\n",
    "def BuildModelNot(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    smote = ADASYN(sampling_strategy= 0.05, random_state=32)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        X=X_train[ttrain]\n",
    "        y=y_train[ttrain]\n",
    "        X_train_sm, y_train_sm= smote.fit_sample(X, y)\n",
    "        clf.fit(X_train_sm, y_train_sm)\n",
    "        sc = clf.score(X_train[test], y_train[ttest])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[ttest] = clf.predict_proba(X_train[ttest])\n",
    "        Xr_test += clf.predict_proba(X_test, validate_features=False)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(Xr, y, labels, best, nclass):\n",
    "    pred=[]\n",
    "    for x in Xr:\n",
    "        if x > best:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    print(classification_report(y,pred, target_names=labels, digits=4))\n",
    "    print(confusion_matrix(y, pred, labels=range(nclass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_auc(y_train_set, pred_train_set):\n",
    "    thresholds = np.linspace(0.01, 0.5, 1000)\n",
    "    f1_sc = np.array([f1_score(y_train_set, pred_train_set[:,1] > thr) for thr in thresholds])\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(thresholds, f1_sc, linewidth=4)\n",
    "    plt.ylabel(\"F1 score\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    \n",
    "    best_model_f1 = thresholds[f1_sc.argmax()]\n",
    "    \n",
    "    return best_model_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.2971e-02,  5.1854e-01,  1.0594e-02, ...,  1.1576e+02,\n",
       "         3.1531e+00,  1.8254e+00],\n",
       "       [ 4.4568e-04,  8.7631e-01,  3.5080e-01, ...,  1.1420e+02,\n",
       "         3.1962e+00,  6.6508e+00],\n",
       "       [ 1.1732e-01,  3.3079e-01,  5.7334e-01, ...,  2.5183e+01,\n",
       "         1.4494e+01,  9.3508e+00],\n",
       "       ...,\n",
       "       [-5.3670e-01,  7.8497e-02,  2.6824e-01, ...,  2.4876e+01,\n",
       "         1.4673e+01,  1.1851e+00],\n",
       "       [ 4.6735e-01,  3.9807e-01,  1.4838e-02, ...,  4.3617e+01,\n",
       "         8.3683e+00,  2.5717e+00],\n",
       "       [ 8.3040e-02,  5.4857e-01,  2.4094e-01, ...,  8.4371e+01,\n",
       "         4.3261e+00,  5.8015e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No samples will be generated with the provided ratio settings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-09b0c6ff2bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    warm_start=False)\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNFOLDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-a9bb3334d872>\u001b[0m in \u001b[0;36mBuildModel\u001b[1;34m(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mX_train_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     82\u001b[0m             self.sampling_strategy, y, self._sampling_type)\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\over_sampling\\_adasyn.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mn_samples_generate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio_nn\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples_generate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 raise ValueError(\"No samples will be generated with the\"\n\u001b[0m\u001b[0;32m    132\u001b[0m                                  \" provided ratio settings.\")\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No samples will be generated with the provided ratio settings."
     ]
    }
   ],
   "source": [
    "lr_best = LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "pred_train, pred_test=BuildModel(lr_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.9, 100)\n",
    "f1_sc = np.array([f1_score(y_train,pred_train[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_lr = thresholds[f1_sc.argmax()]\n",
    "print(f1_sc.max())\n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train[:,1],y_train, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test[:,1],y_test, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
    "                       max_features=None, max_leaf_nodes=150,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=None, splitter='best')\n",
    "pred_train_dt, pred_test_dt=BuildModel(dt_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_dt = np.array([f1_score(y_train,pred_train_dt[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_dt, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_dt_f1 = thresholds[f1_sc_dt.argmax()]\n",
    "print(f1_sc_dt.max())\n",
    "print(best_dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_dt[:,1],y_train, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_dt[:,1],y_test, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_imputed_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(dt_best, mean_imputed_df.columns, 'Decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=25, max_features=64, max_leaf_nodes=25,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "pred_train_rf, pred_test_rf = BuildModel(rf_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.8, 100)\n",
    "f1_sc_rf = np.array([f1_score(y_train,pred_train_rf[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_rf, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_rf_f1 = thresholds[f1_sc_rf.argmax()]\n",
    "print('f1 score of random forest: ', f1_sc_rf.max())\n",
    "print(best_rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_rf[:,1],y_train, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "      Normal     0.9237    0.8841    0.9035      3849\n",
    "  Bankruptcy     0.8889    0.9270    0.9075      3849\n",
    "\n",
    "    accuracy                         0.9056      7698\n",
    "   macro avg     0.9063    0.9056    0.9055      7698\n",
    "weighted avg     0.9063    0.9056    0.9055      7698\n",
    "\n",
    "[[3403  446]\n",
    " [ 281 3568]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_rf[:,1],y_test, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(rf_best, mean_imputed_df.columns, 'Random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eta=5, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logitraw', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "pred_train_xgb, pred_test_xgb = BuildModel(xgb_best, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.8, 100)\n",
    "f1_sc_xgb = np.array([f1_score(y_train,pred_train_xgb[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_xgb, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_xgb = thresholds[f1_sc_xgb.argmax()]\n",
    "print(f1_sc_xgb.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_xgb[:,1],y_train, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_xgb[:,1],y_test, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_feature_importance(xgb_best, mean_imputed_df.columns, 'XGboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "\n",
    "lda.fit(X_train, y_train)\n",
    "pred_train_lda, pred_test_lda = BuildModel(lda, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_lda = np.array([f1_score(y_train,pred_train_lda[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_lda, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_lda = thresholds[f1_sc_lda.argmax()]\n",
    "print(f1_sc_lda.max())\n",
    "\n",
    "show_accuracy(pred_train_lda[:,1],y_train, labels, best_thr_lda, nclass)\n",
    "\n",
    "show_accuracy(pred_test_lda[:,1],y_test, labels, best_thr_lda, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
