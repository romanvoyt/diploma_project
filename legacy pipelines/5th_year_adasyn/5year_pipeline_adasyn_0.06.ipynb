{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libs\n",
    "from math import sqrt\n",
    "import random\n",
    "import os\n",
    "\n",
    "#default data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modules for data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/5year.xlsx')\n",
    "data['B'] = (data['B'].index > 5499).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.55472</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-66.5200</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.57752</td>\n",
       "      <td>1.0881</td>\n",
       "      <td>0.32036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>7.2711</td>\n",
       "      <td>4.7343</td>\n",
       "      <td>142.760</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>3.2597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.48465</td>\n",
       "      <td>0.23298</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>1.2757</td>\n",
       "      <td>0.51535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028591</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>6.0911</td>\n",
       "      <td>3.2749</td>\n",
       "      <td>111.140</td>\n",
       "      <td>3.2841</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.22142</td>\n",
       "      <td>0.57751</td>\n",
       "      <td>3.6082</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.162120</td>\n",
       "      <td>3.05900</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>0.67731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123960</td>\n",
       "      <td>0.192290</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.7934</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>71.531</td>\n",
       "      <td>5.1027</td>\n",
       "      <td>5.6188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>-55.9920</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1.2754</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418840</td>\n",
       "      <td>-0.796020</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>2.878700</td>\n",
       "      <td>7.6524</td>\n",
       "      <td>3.3302</td>\n",
       "      <td>147.560</td>\n",
       "      <td>2.4735</td>\n",
       "      <td>5.9299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.55041</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-22.9590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.81682</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>4.0950</td>\n",
       "      <td>106.430</td>\n",
       "      <td>3.4294</td>\n",
       "      <td>3.3622</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2       X3      X4        X5        X6        X7       X8  \\\n",
       "0  0.088238  0.55472  0.01134  1.0205  -66.5200  0.342040  0.109490  0.57752   \n",
       "1 -0.006202  0.48465  0.23298  1.5998    6.1825  0.000000 -0.006202  1.06340   \n",
       "2  0.130240  0.22142  0.57751  3.6082  120.0400  0.187640  0.162120  3.05900   \n",
       "3 -0.089951  0.88700  0.26927  1.5222  -55.9920 -0.073957 -0.089951  0.12740   \n",
       "4  0.048179  0.55041  0.10765  1.2437  -22.9590  0.000000  0.059280  0.81682   \n",
       "\n",
       "       X9      X10  ...       X56       X57      X58       X59      X60  \\\n",
       "0  1.0881  0.32036  ...  0.080955  0.275430  0.91905  0.002024   7.2711   \n",
       "1  1.2757  0.51535  ... -0.028591 -0.012035  1.00470  0.152220   6.0911   \n",
       "2  1.1415  0.67731  ...  0.123960  0.192290  0.87604  0.000000   8.7934   \n",
       "3  1.2754  0.11300  ...  0.418840 -0.796020  0.59074  2.878700   7.6524   \n",
       "4  1.5150  0.44959  ...  0.240400  0.107160  0.77048  0.139380  10.1180   \n",
       "\n",
       "      X61      X62     X63     X64  B  \n",
       "0  4.7343  142.760  2.5568  3.2597  0  \n",
       "1  3.2749  111.140  3.2841  3.3700  0  \n",
       "2  2.9870   71.531  5.1027  5.6188  0  \n",
       "3  3.3302  147.560  2.4735  5.9299  0  \n",
       "4  4.0950  106.430  3.4294  3.3622  0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_headers(df):\n",
    "    cols = ['X' + str(i+1) for i in range(len(df.columns)-1)]\n",
    "    cols.append('Y')\n",
    "    df.columns = cols\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "mean_imputed_df = pd.DataFrame(imputer.fit_transform(data))\n",
    "set_new_headers(mean_imputed_df)\n",
    "\n",
    "data_imp = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed_df['Altman']=1.2*mean_imputed_df['X3']+1.4*mean_imputed_df['X6']+3.3*mean_imputed_df['X7']+0.6*mean_imputed_df['X8']+mean_imputed_df['X9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y</th>\n",
       "      <th>Altman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.55472</td>\n",
       "      <td>0.01134</td>\n",
       "      <td>1.0205</td>\n",
       "      <td>-66.5200</td>\n",
       "      <td>0.342040</td>\n",
       "      <td>0.109490</td>\n",
       "      <td>0.57752</td>\n",
       "      <td>1.0881</td>\n",
       "      <td>0.32036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275430</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>7.2711</td>\n",
       "      <td>4.7343</td>\n",
       "      <td>142.760</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>3.2597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.288393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>0.48465</td>\n",
       "      <td>0.23298</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006202</td>\n",
       "      <td>1.06340</td>\n",
       "      <td>1.2757</td>\n",
       "      <td>0.51535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>1.00470</td>\n",
       "      <td>0.152220</td>\n",
       "      <td>6.0911</td>\n",
       "      <td>3.2749</td>\n",
       "      <td>111.140</td>\n",
       "      <td>3.2841</td>\n",
       "      <td>3.3700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.172849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.130240</td>\n",
       "      <td>0.22142</td>\n",
       "      <td>0.57751</td>\n",
       "      <td>3.6082</td>\n",
       "      <td>120.0400</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.162120</td>\n",
       "      <td>3.05900</td>\n",
       "      <td>1.1415</td>\n",
       "      <td>0.67731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192290</td>\n",
       "      <td>0.87604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.7934</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>71.531</td>\n",
       "      <td>5.1027</td>\n",
       "      <td>5.6188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.467604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.88700</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>1.5222</td>\n",
       "      <td>-55.9920</td>\n",
       "      <td>-0.073957</td>\n",
       "      <td>-0.089951</td>\n",
       "      <td>0.12740</td>\n",
       "      <td>1.2754</td>\n",
       "      <td>0.11300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.796020</td>\n",
       "      <td>0.59074</td>\n",
       "      <td>2.878700</td>\n",
       "      <td>7.6524</td>\n",
       "      <td>3.3302</td>\n",
       "      <td>147.560</td>\n",
       "      <td>2.4735</td>\n",
       "      <td>5.9299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.274586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.55041</td>\n",
       "      <td>0.10765</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-22.9590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059280</td>\n",
       "      <td>0.81682</td>\n",
       "      <td>1.5150</td>\n",
       "      <td>0.44959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107160</td>\n",
       "      <td>0.77048</td>\n",
       "      <td>0.139380</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>4.0950</td>\n",
       "      <td>106.430</td>\n",
       "      <td>3.4294</td>\n",
       "      <td>3.3622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.329896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2       X3      X4        X5        X6        X7       X8  \\\n",
       "0  0.088238  0.55472  0.01134  1.0205  -66.5200  0.342040  0.109490  0.57752   \n",
       "1 -0.006202  0.48465  0.23298  1.5998    6.1825  0.000000 -0.006202  1.06340   \n",
       "2  0.130240  0.22142  0.57751  3.6082  120.0400  0.187640  0.162120  3.05900   \n",
       "3 -0.089951  0.88700  0.26927  1.5222  -55.9920 -0.073957 -0.089951  0.12740   \n",
       "4  0.048179  0.55041  0.10765  1.2437  -22.9590  0.000000  0.059280  0.81682   \n",
       "\n",
       "       X9      X10  ...       X57      X58       X59      X60     X61  \\\n",
       "0  1.0881  0.32036  ...  0.275430  0.91905  0.002024   7.2711  4.7343   \n",
       "1  1.2757  0.51535  ... -0.012035  1.00470  0.152220   6.0911  3.2749   \n",
       "2  1.1415  0.67731  ...  0.192290  0.87604  0.000000   8.7934  2.9870   \n",
       "3  1.2754  0.11300  ... -0.796020  0.59074  2.878700   7.6524  3.3302   \n",
       "4  1.5150  0.44959  ...  0.107160  0.77048  0.139380  10.1180  4.0950   \n",
       "\n",
       "       X62     X63     X64    Y    Altman  \n",
       "0  142.760  2.5568  3.2597  0.0  2.288393  \n",
       "1  111.140  3.2841  3.3700  0.0  2.172849  \n",
       "2   71.531  5.1027  5.6188  0.0  4.467604  \n",
       "3  147.560  2.4735  5.9299  0.0  1.274586  \n",
       "4  106.430  3.4294  3.3622  0.0  2.329896  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = mean_imputed_df['Y'].values\n",
    "mean_imputed_df.drop('Y', axis=1, inplace=True)\n",
    "X = mean_imputed_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "nfolds = 10\n",
    "nclass = 2\n",
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "\n",
    "cross_val = StratifiedKFold(nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model objects\n",
    "## Tuning model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(model, features, model_name):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    results=pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\n",
    "    results=results.sort_values('importance', ascending=False)\n",
    "    results.head(70)\n",
    "#     results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh',\n",
    "#                      color = 'red', edgecolor = 'k', title = 'Feature Importances of ' + model_name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137 1773\n"
     ]
    }
   ],
   "source": [
    "ntrain=X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "nclass = 2\n",
    "SEED = 42\n",
    "NFOLDS = 10\n",
    "print(ntrain, ntest)\n",
    "kf = KFold(n_splits=NFOLDS, random_state=SEED, shuffle=True)\n",
    "labels = ['Normal','Bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    smote = ADASYN(sampling_strategy=0.06, random_state=32)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        X=X_train[ttrain]\n",
    "        y=y_train[ttrain]\n",
    "        X_train_sm, y_train_sm= smote.fit_sample(X, y)\n",
    "        clf.fit(X_train_sm, y_train_sm)\n",
    "        sc = clf.score(X_train[ttest], y_train[ttest])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[ttest] = clf.predict_proba(X_train[ttest])\n",
    "        Xr_test += clf.predict_proba(X_test)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test\n",
    "\n",
    "\n",
    "def BuildModelNot(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    smote = ADASYN(sampling_strategy=0.06, random_state=32)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        X=X_train[ttrain]\n",
    "        y=y_train[ttrain]\n",
    "        X_train_sm, y_train_sm= smote.fit_sample(X, y)\n",
    "        clf.fit(X_train_sm, y_train_sm)\n",
    "        sc = clf.score(X_train[test], y_train[ttest])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[ttest] = clf.predict_proba(X_train[ttest])\n",
    "        Xr_test += clf.predict_proba(X_test, validate_features=False)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(Xr, y, labels, best, nclass):\n",
    "    pred=[]\n",
    "    for x in Xr:\n",
    "        if x > best:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    print(classification_report(y,pred, target_names=labels, digits=4))\n",
    "    print(confusion_matrix(y, pred, labels=range(nclass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_auc(y_train_set, pred_train_set):\n",
    "    thresholds = np.linspace(0.01, 0.5, 1000)\n",
    "    f1_sc = np.array([f1_score(y_train_set, pred_train_set[:,1] > thr) for thr in thresholds])\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(thresholds, f1_sc, linewidth=4)\n",
    "    plt.ylabel(\"F1 score\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    \n",
    "    best_model_f1 = thresholds[f1_sc.argmax()]\n",
    "    \n",
    "    return best_model_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.5517000e-01,  1.1159000e+00, -2.8003000e-01, ...,\n",
       "         2.5052000e+00,  9.1922000e+00, -1.9476250e+00],\n",
       "       [ 6.1432000e-02,  3.7332000e-01,  4.0756000e-01, ...,\n",
       "         4.5888000e+00,  2.7576000e+00,  2.7652814e+00],\n",
       "       [ 1.2821000e-02,  1.0224000e+00, -4.9113000e-01, ...,\n",
       "         1.0049000e+00,  2.1915000e+00,  3.0168110e-01],\n",
       "       ...,\n",
       "       [ 1.5170000e-03,  3.2977000e-01,  4.1835000e-01, ...,\n",
       "         3.1041000e+00,  2.8378000e+00,  2.5887461e+00],\n",
       "       [-5.1330000e-02,  1.1395000e-01,  3.7597000e-01, ...,\n",
       "         1.2697000e+01,  2.6669000e+00,  6.3223750e+00],\n",
       "       [ 8.1354000e-02,  6.4064000e-01,  2.4803000e-01, ...,\n",
       "         1.9056000e+00,  9.5881000e+00,  2.3173662e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-09b0c6ff2bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    warm_start=False)\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNFOLDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-4c861866f125>\u001b[0m in \u001b[0;36mBuildModel\u001b[1;34m(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mX_train_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[1;32m---> 82\u001b[1;33m             self.sampling_strategy, y, self._sampling_type)\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m                 .format(sampling_strategy))\n\u001b[0;32m    463\u001b[0m         return OrderedDict(sorted(\n\u001b[1;32m--> 464\u001b[1;33m             \u001b[0m_sampling_strategy_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m             .items()))\n\u001b[0;32m    466\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36m_sampling_strategy_float\u001b[1;34m(sampling_strategy, y, sampling_type)\u001b[0m\n\u001b[0;32m    318\u001b[0m         }\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msampling_strategy_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             raise ValueError(\"The specified ratio required to remove samples \"\n\u001b[0m\u001b[0;32m    321\u001b[0m                              \u001b[1;34m\"from the minority class while trying to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                              \u001b[1;34m\"generate new samples. Please increase the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio."
     ]
    }
   ],
   "source": [
    "lr_best = LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "pred_train, pred_test=BuildModel(lr_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.9, 100)\n",
    "f1_sc = np.array([f1_score(y_train,pred_train[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_lr = thresholds[f1_sc.argmax()]\n",
    "print(f1_sc.max())\n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train[:,1],y_train, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test[:,1],y_test, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
    "                       max_features=None, max_leaf_nodes=150,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=None, splitter='best')\n",
    "pred_train_dt, pred_test_dt=BuildModel(dt_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_dt = np.array([f1_score(y_train,pred_train_dt[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_dt, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_dt_f1 = thresholds[f1_sc_dt.argmax()]\n",
    "print(f1_sc_dt.max())\n",
    "print(best_dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_dt[:,1],y_train, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_dt[:,1],y_test, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_imputed_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(dt_best, mean_imputed_df.columns, 'Decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=25, max_features=64, max_leaf_nodes=25,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "pred_train_rf, pred_test_rf = BuildModel(rf_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.8, 100)\n",
    "f1_sc_rf = np.array([f1_score(y_train,pred_train_rf[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_rf, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_rf_f1 = thresholds[f1_sc_rf.argmax()]\n",
    "print('f1 score of random forest: ', f1_sc_rf.max())\n",
    "print(best_rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_rf[:,1],y_train, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "      Normal     0.9237    0.8841    0.9035      3849\n",
    "  Bankruptcy     0.8889    0.9270    0.9075      3849\n",
    "\n",
    "    accuracy                         0.9056      7698\n",
    "   macro avg     0.9063    0.9056    0.9055      7698\n",
    "weighted avg     0.9063    0.9056    0.9055      7698\n",
    "\n",
    "[[3403  446]\n",
    " [ 281 3568]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_rf[:,1],y_test, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(rf_best, mean_imputed_df.columns, 'Random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eta=5, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logitraw', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "pred_train_xgb, pred_test_xgb = BuildModel(xgb_best, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.8, 100)\n",
    "f1_sc_xgb = np.array([f1_score(y_train,pred_train_xgb[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_xgb, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_xgb = thresholds[f1_sc_xgb.argmax()]\n",
    "print(f1_sc_xgb.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_xgb[:,1],y_train, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_xgb[:,1],y_test, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_feature_importance(xgb_best, mean_imputed_df.columns, 'XGboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "\n",
    "lda.fit(X_train, y_train)\n",
    "pred_train_lda, pred_test_lda = BuildModel(lda, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_lda = np.array([f1_score(y_train,pred_train_lda[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_lda, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_lda = thresholds[f1_sc_lda.argmax()]\n",
    "print(f1_sc_lda.max())\n",
    "\n",
    "show_accuracy(pred_train_lda[:,1],y_train, labels, best_thr_lda, nclass)\n",
    "show_accuracy(pred_test_lda[:,1],y_test, labels, best_thr_lda, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
