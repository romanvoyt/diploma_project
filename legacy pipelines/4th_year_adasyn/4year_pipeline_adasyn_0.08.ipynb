{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libs\n",
    "from math import sqrt\n",
    "import random\n",
    "import os\n",
    "\n",
    "#default data science libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#modules for data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve, KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#classification models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#evaluation metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/4year.xlsx')\n",
    "data['B'] = (data['B'].index > 9276).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.159290</td>\n",
       "      <td>0.46240</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>1.1683</td>\n",
       "      <td>-44.853</td>\n",
       "      <td>0.467020</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.82895</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>0.38330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108990</td>\n",
       "      <td>0.41557</td>\n",
       "      <td>0.89101</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>7.7928</td>\n",
       "      <td>4.9914</td>\n",
       "      <td>119.810</td>\n",
       "      <td>3.0465</td>\n",
       "      <td>3.0560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.127430</td>\n",
       "      <td>0.46243</td>\n",
       "      <td>0.26917</td>\n",
       "      <td>1.7517</td>\n",
       "      <td>7.597</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>-0.127430</td>\n",
       "      <td>1.16250</td>\n",
       "      <td>1.2944</td>\n",
       "      <td>0.53757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089372</td>\n",
       "      <td>-0.23704</td>\n",
       "      <td>1.06250</td>\n",
       "      <td>0.150410</td>\n",
       "      <td>5.4327</td>\n",
       "      <td>3.4629</td>\n",
       "      <td>100.970</td>\n",
       "      <td>3.6150</td>\n",
       "      <td>3.4725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.070488</td>\n",
       "      <td>0.23570</td>\n",
       "      <td>0.52781</td>\n",
       "      <td>3.2393</td>\n",
       "      <td>125.680</td>\n",
       "      <td>0.163670</td>\n",
       "      <td>0.086895</td>\n",
       "      <td>2.87180</td>\n",
       "      <td>1.0574</td>\n",
       "      <td>0.67689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054286</td>\n",
       "      <td>0.10413</td>\n",
       "      <td>0.94571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.1070</td>\n",
       "      <td>3.3808</td>\n",
       "      <td>76.076</td>\n",
       "      <td>4.7978</td>\n",
       "      <td>4.7818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>0.40538</td>\n",
       "      <td>0.31543</td>\n",
       "      <td>1.8705</td>\n",
       "      <td>19.115</td>\n",
       "      <td>0.504970</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>1.45390</td>\n",
       "      <td>1.1144</td>\n",
       "      <td>0.58938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.23203</td>\n",
       "      <td>0.89737</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>6.1384</td>\n",
       "      <td>4.2241</td>\n",
       "      <td>88.299</td>\n",
       "      <td>4.1337</td>\n",
       "      <td>4.6484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.69793</td>\n",
       "      <td>0.18878</td>\n",
       "      <td>1.2713</td>\n",
       "      <td>-15.344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.43282</td>\n",
       "      <td>1.7350</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439880</td>\n",
       "      <td>-0.36440</td>\n",
       "      <td>0.57153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.8010</td>\n",
       "      <td>2.7925</td>\n",
       "      <td>146.390</td>\n",
       "      <td>2.4934</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2       X3      X4       X5        X6        X7       X8  \\\n",
       "0  0.159290  0.46240  0.07773  1.1683  -44.853  0.467020  0.189480  0.82895   \n",
       "1 -0.127430  0.46243  0.26917  1.7517    7.597  0.000925 -0.127430  1.16250   \n",
       "2  0.070488  0.23570  0.52781  3.2393  125.680  0.163670  0.086895  2.87180   \n",
       "3  0.136760  0.40538  0.31543  1.8705   19.115  0.504970  0.136760  1.45390   \n",
       "4 -0.110080  0.69793  0.18878  1.2713  -15.344  0.000000 -0.110080  0.43282   \n",
       "\n",
       "       X9      X10  ...       X56      X57      X58       X59      X60  \\\n",
       "0  1.1223  0.38330  ...  0.108990  0.41557  0.89101  0.001422   7.7928   \n",
       "1  1.2944  0.53757  ... -0.089372 -0.23704  1.06250  0.150410   5.4327   \n",
       "2  1.0574  0.67689  ...  0.054286  0.10413  0.94571  0.000000   7.1070   \n",
       "3  1.1144  0.58938  ...  0.102630  0.23203  0.89737  0.073024   6.1384   \n",
       "4  1.7350  0.30207  ...  0.439880 -0.36440  0.57153  0.000000  18.8010   \n",
       "\n",
       "      X61      X62     X63      X64  B  \n",
       "0  4.9914  119.810  3.0465   3.0560  0  \n",
       "1  3.4629  100.970  3.6150   3.4725  0  \n",
       "2  3.3808   76.076  4.7978   4.7818  0  \n",
       "3  4.2241   88.299  4.1337   4.6484  0  \n",
       "4  2.7925  146.390  2.4934  15.0360  0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_headers(df):\n",
    "    cols = ['X' + str(i+1) for i in range(len(df.columns)-1)]\n",
    "    cols.append('Y')\n",
    "    df.columns = cols\n",
    "\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n",
    "mean_imputed_df = pd.DataFrame(imputer.fit_transform(data))\n",
    "set_new_headers(mean_imputed_df)\n",
    "\n",
    "data_imp = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed_df['Altman']=1.2*mean_imputed_df['X3']+1.4*mean_imputed_df['X6']+3.3*mean_imputed_df['X7']+0.6*mean_imputed_df['X8']+mean_imputed_df['X9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Y</th>\n",
       "      <th>Altman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.159290</td>\n",
       "      <td>0.46240</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>1.1683</td>\n",
       "      <td>-44.853</td>\n",
       "      <td>0.467020</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.82895</td>\n",
       "      <td>1.1223</td>\n",
       "      <td>0.38330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41557</td>\n",
       "      <td>0.89101</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>7.7928</td>\n",
       "      <td>4.9914</td>\n",
       "      <td>119.810</td>\n",
       "      <td>3.0465</td>\n",
       "      <td>3.0560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.992058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.127430</td>\n",
       "      <td>0.46243</td>\n",
       "      <td>0.26917</td>\n",
       "      <td>1.7517</td>\n",
       "      <td>7.597</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>-0.127430</td>\n",
       "      <td>1.16250</td>\n",
       "      <td>1.2944</td>\n",
       "      <td>0.53757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23704</td>\n",
       "      <td>1.06250</td>\n",
       "      <td>0.150410</td>\n",
       "      <td>5.4327</td>\n",
       "      <td>3.4629</td>\n",
       "      <td>100.970</td>\n",
       "      <td>3.6150</td>\n",
       "      <td>3.4725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.895680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.070488</td>\n",
       "      <td>0.23570</td>\n",
       "      <td>0.52781</td>\n",
       "      <td>3.2393</td>\n",
       "      <td>125.680</td>\n",
       "      <td>0.163670</td>\n",
       "      <td>0.086895</td>\n",
       "      <td>2.87180</td>\n",
       "      <td>1.0574</td>\n",
       "      <td>0.67689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10413</td>\n",
       "      <td>0.94571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.1070</td>\n",
       "      <td>3.3808</td>\n",
       "      <td>76.076</td>\n",
       "      <td>4.7978</td>\n",
       "      <td>4.7818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.929743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>0.40538</td>\n",
       "      <td>0.31543</td>\n",
       "      <td>1.8705</td>\n",
       "      <td>19.115</td>\n",
       "      <td>0.504970</td>\n",
       "      <td>0.136760</td>\n",
       "      <td>1.45390</td>\n",
       "      <td>1.1144</td>\n",
       "      <td>0.58938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23203</td>\n",
       "      <td>0.89737</td>\n",
       "      <td>0.073024</td>\n",
       "      <td>6.1384</td>\n",
       "      <td>4.2241</td>\n",
       "      <td>88.299</td>\n",
       "      <td>4.1337</td>\n",
       "      <td>4.6484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.523522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.69793</td>\n",
       "      <td>0.18878</td>\n",
       "      <td>1.2713</td>\n",
       "      <td>-15.344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110080</td>\n",
       "      <td>0.43282</td>\n",
       "      <td>1.7350</td>\n",
       "      <td>0.30207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.36440</td>\n",
       "      <td>0.57153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.8010</td>\n",
       "      <td>2.7925</td>\n",
       "      <td>146.390</td>\n",
       "      <td>2.4934</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.857964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2       X3      X4       X5        X6        X7       X8  \\\n",
       "0  0.159290  0.46240  0.07773  1.1683  -44.853  0.467020  0.189480  0.82895   \n",
       "1 -0.127430  0.46243  0.26917  1.7517    7.597  0.000925 -0.127430  1.16250   \n",
       "2  0.070488  0.23570  0.52781  3.2393  125.680  0.163670  0.086895  2.87180   \n",
       "3  0.136760  0.40538  0.31543  1.8705   19.115  0.504970  0.136760  1.45390   \n",
       "4 -0.110080  0.69793  0.18878  1.2713  -15.344  0.000000 -0.110080  0.43282   \n",
       "\n",
       "       X9      X10  ...      X57      X58       X59      X60     X61      X62  \\\n",
       "0  1.1223  0.38330  ...  0.41557  0.89101  0.001422   7.7928  4.9914  119.810   \n",
       "1  1.2944  0.53757  ... -0.23704  1.06250  0.150410   5.4327  3.4629  100.970   \n",
       "2  1.0574  0.67689  ...  0.10413  0.94571  0.000000   7.1070  3.3808   76.076   \n",
       "3  1.1144  0.58938  ...  0.23203  0.89737  0.073024   6.1384  4.2241   88.299   \n",
       "4  1.7350  0.30207  ... -0.36440  0.57153  0.000000  18.8010  2.7925  146.390   \n",
       "\n",
       "      X63      X64    Y    Altman  \n",
       "0  3.0465   3.0560  0.0  2.992058  \n",
       "1  3.6150   3.4725  0.0  1.895680  \n",
       "2  4.7978   4.7818  0.0  3.929743  \n",
       "3  4.1337   4.6484  0.0  3.523522  \n",
       "4  2.4934  15.0360  0.0  1.857964  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = mean_imputed_df['Y'].values\n",
    "mean_imputed_df.drop('Y', axis=1, inplace=True)\n",
    "X = mean_imputed_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "nfolds = 10\n",
    "nclass = 2\n",
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "\n",
    "cross_val = StratifiedKFold(nfolds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model objects\n",
    "## Tuning model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importance(model, features, model_name):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    results=pd.DataFrame({'feature': features, 'importance': model.feature_importances_})\n",
    "    results=results.sort_values('importance', ascending=False)\n",
    "    results.head(70)\n",
    "#     results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh',\n",
    "#                      color = 'red', edgecolor = 'k', title = 'Feature Importances of ' + model_name)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6854 2938\n"
     ]
    }
   ],
   "source": [
    "ntrain=X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "nclass = 2\n",
    "SEED = 42\n",
    "NFOLDS = 10\n",
    "print(ntrain, ntest)\n",
    "kf = KFold(n_splits=NFOLDS, random_state=SEED, shuffle=True)\n",
    "labels = ['Normal','Bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    smote = ADASYN(sampling_strategy=0.08, random_state=32)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        X=X_train[ttrain]\n",
    "        y=y_train[ttrain]\n",
    "        X_train_sm, y_train_sm= smote.fit_sample(X, y)\n",
    "        clf.fit(X_train_sm, y_train_sm)\n",
    "        sc = clf.score(X_train[ttest], y_train[ttest])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[ttest] = clf.predict_proba(X_train[ttest])\n",
    "        Xr_test += clf.predict_proba(X_test)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test\n",
    "\n",
    "\n",
    "def BuildModelNot(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS):\n",
    "    Xr_train = np.zeros((ntrain, nclass))\n",
    "    Xr_test = np.zeros((ntest, nclass))\n",
    "    tr_ind = np.arange(ntrain)\n",
    "    smote = ADASYN(sampling_strategy=0.08, random_state=32)\n",
    "    for i, (ttrain, ttest) in enumerate(kf.split(tr_ind)):\n",
    "        clf = best_alg\n",
    "        X=X_train[ttrain]\n",
    "        y=y_train[ttrain]\n",
    "        X_train_sm, y_train_sm= smote.fit_sample(X, y)\n",
    "        clf.fit(X_train_sm, y_train_sm)\n",
    "        sc = clf.score(X_train[test], y_train[ttest])\n",
    "        print(i, 'accuracy', sc)\n",
    "        Xr_train[ttest] = clf.predict_proba(X_train[ttest])\n",
    "        Xr_test += clf.predict_proba(X_test, validate_features=False)/NFOLDS\n",
    "    \n",
    "    return Xr_train, Xr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(Xr, y, labels, best, nclass):\n",
    "    pred=[]\n",
    "    for x in Xr:\n",
    "        if x > best:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    print(classification_report(y,pred, target_names=labels, digits=4))\n",
    "    print(confusion_matrix(y, pred, labels=range(nclass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_auc(y_train_set, pred_train_set):\n",
    "    thresholds = np.linspace(0.01, 0.5, 1000)\n",
    "    f1_sc = np.array([f1_score(y_train_set, pred_train_set[:,1] > thr) for thr in thresholds])\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.plot(thresholds, f1_sc, linewidth=4)\n",
    "    plt.ylabel(\"F1 score\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    \n",
    "    best_model_f1 = thresholds[f1_sc.argmax()]\n",
    "    \n",
    "    return best_model_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.50190000e-03,  5.64010000e-01,  1.27340000e-01, ...,\n",
       "         4.33350000e+00,  7.20950000e+00,  2.98549455e+00],\n",
       "       [ 9.25940000e-02,  4.23930000e-01,  1.12350000e-01, ...,\n",
       "         4.94350000e+00,  4.50660000e+00,  3.57897020e+00],\n",
       "       [ 5.91290000e-03,  5.67230000e-02,  6.28140000e-01, ...,\n",
       "         1.60000000e+01,  2.87990000e+00,  1.18092914e+01],\n",
       "       ...,\n",
       "       [-2.81220000e-02,  7.17190000e-01,  6.35570000e-02, ...,\n",
       "         2.24690000e+00,  3.67500000e+00,  1.72114040e+00],\n",
       "       [ 1.49070000e-01,  1.41550000e-01,  4.00110000e-01, ...,\n",
       "         3.67510000e+01,  1.12780000e+01,  9.78746300e+00],\n",
       "       [-2.55790000e-01,  7.87930000e-01,  8.16130000e-02, ...,\n",
       "         4.18310000e+00,  2.48550000e+01,  2.51142060e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No samples will be generated with the provided ratio settings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-09b0c6ff2bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    warm_start=False)\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBuildModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNFOLDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-be4cb0e8b7f6>\u001b[0m in \u001b[0;36mBuildModel\u001b[1;34m(best_alg, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NfOLDS)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mX_train_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mttest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     82\u001b[0m             self.sampling_strategy, y, self._sampling_type)\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developement\\Anaconda\\lib\\site-packages\\imblearn\\over_sampling\\_adasyn.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mn_samples_generate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio_nn\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples_generate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                 raise ValueError(\"No samples will be generated with the\"\n\u001b[0m\u001b[0;32m    132\u001b[0m                                  \" provided ratio settings.\")\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No samples will be generated with the provided ratio settings."
     ]
    }
   ],
   "source": [
    "lr_best = LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "pred_train, pred_test=BuildModel(lr_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.9, 100)\n",
    "f1_sc = np.array([f1_score(y_train,pred_train[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_lr = thresholds[f1_sc.argmax()]\n",
    "print(f1_sc.max())\n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train[:,1],y_train, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test[:,1],y_test, labels, best_lr, nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
    "                       max_features=None, max_leaf_nodes=150,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=None, splitter='best')\n",
    "pred_train_dt, pred_test_dt=BuildModel(dt_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_dt = np.array([f1_score(y_train,pred_train_dt[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_dt, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_dt_f1 = thresholds[f1_sc_dt.argmax()]\n",
    "print(f1_sc_dt.max())\n",
    "print(best_dt_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_dt[:,1],y_train, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_dt[:,1],y_test, labels, best_dt_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_imputed_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(dt_best, mean_imputed_df.columns, 'Decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=25, max_features=64, max_leaf_nodes=25,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "\n",
    "pred_train_rf, pred_test_rf = BuildModel(rf_best, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.8, 100)\n",
    "f1_sc_rf = np.array([f1_score(y_train,pred_train_rf[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_rf, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_rf_f1 = thresholds[f1_sc_rf.argmax()]\n",
    "print('f1 score of random forest: ', f1_sc_rf.max())\n",
    "print(best_rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_rf[:,1],y_train, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "      Normal     0.9237    0.8841    0.9035      3849\n",
    "  Bankruptcy     0.8889    0.9270    0.9075      3849\n",
    "\n",
    "    accuracy                         0.9056      7698\n",
    "   macro avg     0.9063    0.9056    0.9055      7698\n",
    "weighted avg     0.9063    0.9056    0.9055      7698\n",
    "\n",
    "[[3403  446]\n",
    " [ 281 3568]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_rf[:,1],y_test, labels, best_rf_f1, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(rf_best, mean_imputed_df.columns, 'Random forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, eta=5, gamma=0,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
    "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logitraw', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "pred_train_xgb, pred_test_xgb = BuildModel(xgb_best, X_train, y_train, X_test, kf, ntrain, ntest, nclass, NFOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.01, 0.8, 100)\n",
    "f1_sc_xgb = np.array([f1_score(y_train,pred_train_xgb[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_xgb, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_xgb = thresholds[f1_sc_xgb.argmax()]\n",
    "print(f1_sc_xgb.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_train_xgb[:,1],y_train, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(pred_test_xgb[:,1],y_test, labels, best_thr_xgb, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_feature_importance(xgb_best, mean_imputed_df.columns, 'XGboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA()\n",
    "\n",
    "lda.fit(X_train, y_train)\n",
    "pred_train_lda, pred_test_lda = BuildModel(lda, X_train, y_train, X_test,kf, ntrain, ntest, nclass, NFOLDS)\n",
    "\n",
    "thresholds = np.linspace(0.01, 0.5, 100)\n",
    "f1_sc_lda = np.array([f1_score(y_train,pred_train_lda[:,1] > thr) for thr in thresholds])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(thresholds, f1_sc_lda, linewidth=4 )\n",
    "plt.ylabel(\"F1 score\", fontsize=18)\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "best_thr_lda = thresholds[f1_sc_lda.argmax()]\n",
    "print(f1_sc_lda.max())\n",
    "\n",
    "show_accuracy(pred_train_lda[:,1],y_train, labels, best_thr_lda, nclass)\n",
    "show_accuracy(pred_test_lda[:,1],y_test, labels, best_thr_lda, nclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
